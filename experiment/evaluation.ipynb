{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e792e5b",
   "metadata": {},
   "source": [
    "# Notebook for running evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72085ccb",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0f6192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No abbreviations file found for en. Using default abbreviations.\n",
      "No abbreviations file found for en. Using default abbreviations.\n",
      "No abbreviations file found for en. Using default abbreviations.\n",
      "Calculating embeddings: 16it [00:22,  1.41s/it]\n",
      "No abbreviations file found for en. Using default abbreviations.\n",
      "Calculating embeddings: 16it [00:23,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from experiment.evaluations import evaluate_dispatching, evaluate_llm_only, evaluate_baseline_rag, evaluate_reranker_rag, evaluate_dense_rag, evaluate_dense_reranker_rag\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "PROJECT_DIR = os.path.join(ROOT_DIR, \"master-thesis-project\")\n",
    "EXPERIMENT_DIR = os.path.join(PROJECT_DIR, \"experiment\")\n",
    "DATASET_DIR = os.path.join(EXPERIMENT_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb003a7",
   "metadata": {},
   "source": [
    "Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e596d6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features in dataset: ['user_input', 'retrieved_contexts', 'response']\n",
      "Total samples in dataset: 206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0c205f31af40e79d57910eaa5409e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[598]: OutputParserException(Invalid json output: The statements are all explicitly supported by the provided context. Therefore, the verdicts for each statement are as follows:\n",
      "\n",
      "1. \"When living abroad as a pensioner, an individual must apply for health insurance coverage in the country of residence.\" - The context states that pensioners living abroad must apply to be covered by the health insurance of their country of residence. Verdict: 1\n",
      "2. \"If the country of residence is within the European Union, European Economic Area, Switzerland, or the United Kingdom, the application must be made using form E121.\" - The context explicitly mentions that for EU/EEA countries, Switzerland, or the UK, the application must be made using form E121. Verdict: 1\n",
      "3. \"Family members of the pensioner may also be eligible for health insurance coverage if they meet certain conditions.\" - The context states that family members can also get health insurance via form E121 if conditions are met. Verdict: 1\n",
      "4. \"The eligibility of family members depends on specific criteria established by relevant authorities.\" - The context indicates that family members not meeting certain criteria need to contact authorities to evaluate eligibility, implying that eligibility depends on criteria set by authorities. Verdict: 1\n",
      "5. \"For countries outside the European Union, European Economic Area, Switzerland, or the United Kingdom, an individual must contact local health authorities to obtain health insurance coverage.\" - The context states that for non-EU/EEA countries, contact with local health authorities is required. Verdict: 1\n",
      "6. \"If public health insurance is not available in the country of residence, a private consultation with healthcare providers is recommended.\" - The context mentions that if public health insurance is unavailable, private healthcare providers should be contacted. Verdict: 1\n",
      "7. \"Pensioners can use the EU/EEA/UK blue health insurance card to receive temporary medical treatment during travels within these regions.\" - The context confirms that pensioners can use the EU/EEA/UK blue health insurance card for treatment during travels within these regions. Verdict: 1\n",
      "\n",
      "{\n",
      "  \"statements\": [\n",
      "    {\n",
      "      \"statement\": \"When living abroad as a pensioner, an individual must apply for health insurance coverage in the country of residence.\",\n",
      "      \"reason\": \"The context states that pensioners living abroad must apply to be covered by the health insurance of their country of residence.\",\n",
      "      \"verdict\": 1\n",
      "    },\n",
      "    {\n",
      "      \"statement\": \"If the country of residence is within the European Union, European Economic Area, Switzerland, or the United Kingdom, the application must be made using form E121.\",\n",
      "      \"reason\": \"The context explicitly mentions that for EU/EEA countries, Switzerland, or the UK, the application must be made using form E121.\",\n",
      "      \"verdict\": 1\n",
      "    },\n",
      "    {\n",
      "      \"statement\": \"Family members of the pensioner may also be eligible for health insurance coverage if they meet certain conditions.\",\n",
      "      \"reason\": \"The context states that family members can also get health insurance via form E121 if conditions are met.\",\n",
      "      \"verdict\": 1\n",
      "    },\n",
      "    {\n",
      "      \"statement\": \"The eligibility of family members depends on specific criteria established by relevant authorities.\",\n",
      "      \"reason\": \"The context indicates that family members not meeting certain criteria need to contact authorities to evaluate eligibility, implying that eligibility depends on criteria set by authorities.\",\n",
      "      \"verdict\": 1\n",
      "    },\n",
      "    {\n",
      "      \"statement\": \"For countries outside the European Union, European Economic Area, Switzerland, or the United Kingdom, an individual must contact local health authorities to obtain health insurance coverage.\",\n",
      "      \"reason\": \"The context states that for non-EU/EEA countries, contact with local health authorities is required.\",\n",
      "      \"verdict\": 1\n",
      "    },\n",
      "    {\n",
      "      \"statement\": \"If public health insurance is not available in the country of residence, a private consultation with healthcare providers is recommended.\",\n",
      "      \"reason\": \"The context mentions that if public health insurance is unavailable, private healthcare providers should be contacted.\",\n",
      "      \"verdict\": 1\n",
      "    },\n",
      "    {\n",
      "      \"statement\": \"Pensioners can use the EU/EEA/UK blue health insurance card to receive temporary medical treatment during travels within these regions.\",\n",
      "      \"reason\": \"The context confirms that pensioners can use the EU/EEA/UK blue health insurance card for treatment during travels within these regions.\",\n",
      "      \"verdict\": 1\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "Processing item 1/206\n",
      "How ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 2/206\n",
      "How ...\n",
      "Processing item 3/206\n",
      "What...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 4/206\n",
      "When...\n",
      "Processing item 5/206\n",
      "How ...\n",
      "Processing item 6/206\n",
      "What...\n",
      "Processing item 7/206\n",
      "Can ...\n",
      "Processing item 8/206\n",
      "How ...\n",
      "Processing item 9/206\n",
      "Wher...\n",
      "Processing item 10/206\n",
      "What...\n",
      "Processing item 11/206\n",
      "How ...\n",
      "Processing item 12/206\n",
      "What...\n",
      "Processing item 13/206\n",
      "Can ...\n",
      "Processing item 14/206\n",
      "How ...\n",
      "Processing item 15/206\n",
      "What...\n",
      "Processing item 16/206\n",
      "How ...\n",
      "Processing item 17/206\n",
      "Can ...\n",
      "Processing item 18/206\n",
      "Can ...\n",
      "Processing item 19/206\n",
      "What...\n",
      "Processing item 20/206\n",
      "How ...\n",
      "Processing item 21/206\n",
      "Who ...\n",
      "Processing item 22/206\n",
      "Can ...\n",
      "Processing item 23/206\n",
      "What...\n",
      "Processing item 24/206\n",
      "How ...\n",
      "Processing item 25/206\n",
      "What...\n",
      "Processing item 26/206\n",
      "What...\n",
      "Processing item 27/206\n",
      "How ...\n",
      "Processing item 28/206\n",
      "Wher...\n",
      "Processing item 29/206\n",
      "What...\n",
      "Processing item 30/206\n",
      "Can ...\n",
      "Processing item 31/206\n",
      "Are ...\n",
      "Processing item 32/206\n",
      "How ...\n",
      "Processing item 33/206\n",
      "How ...\n",
      "Processing item 34/206\n",
      "What...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 35/206\n",
      "How ...\n",
      "Processing item 36/206\n",
      "Can ...\n",
      "Processing item 37/206\n",
      "How ...\n",
      "Processing item 38/206\n",
      "What...\n",
      "Processing item 39/206\n",
      "What...\n",
      "Processing item 40/206\n",
      "Do I...\n",
      "Processing item 41/206\n",
      "How ...\n",
      "Processing item 42/206\n",
      "How ...\n",
      "Processing item 43/206\n",
      "Do I...\n",
      "Processing item 44/206\n",
      "What...\n",
      "Processing item 45/206\n",
      "Can ...\n",
      "Processing item 46/206\n",
      "How ...\n",
      "Processing item 47/206\n",
      "What...\n",
      "Processing item 48/206\n",
      "Can ...\n",
      "Processing item 49/206\n",
      "Can ...\n",
      "Processing item 50/206\n",
      "What...\n",
      "Processing item 51/206\n",
      "Can ...\n",
      "Processing item 52/206\n",
      "Is i...\n",
      "Processing item 53/206\n",
      "How ...\n",
      "Processing item 54/206\n",
      "What...\n",
      "Processing item 55/206\n",
      "What...\n",
      "Processing item 56/206\n",
      "How ...\n",
      "Processing item 57/206\n",
      "Are ...\n",
      "Processing item 58/206\n",
      "What...\n",
      "Processing item 59/206\n",
      "How ...\n",
      "Processing item 60/206\n",
      "What...\n",
      "Processing item 61/206\n",
      "Can ...\n",
      "Processing item 62/206\n",
      "What...\n",
      "Processing item 63/206\n",
      "What...\n",
      "Processing item 64/206\n",
      "How ...\n",
      "Processing item 65/206\n",
      "Are ...\n",
      "Processing item 66/206\n",
      "What...\n",
      "Processing item 67/206\n",
      "How ...\n",
      "Processing item 68/206\n",
      "What...\n",
      "Processing item 69/206\n",
      "What...\n",
      "Processing item 70/206\n",
      "How ...\n",
      "Processing item 71/206\n",
      "What...\n",
      "Processing item 72/206\n",
      "What...\n",
      "Processing item 73/206\n",
      "Can ...\n",
      "Processing item 74/206\n",
      "How ...\n",
      "Processing item 75/206\n",
      "What...\n",
      "Processing item 76/206\n",
      "Are ...\n",
      "Processing item 77/206\n",
      "What...\n",
      "Processing item 78/206\n",
      "Can ...\n",
      "Processing item 79/206\n",
      "What...\n",
      "Processing item 80/206\n",
      "How ...\n",
      "Processing item 81/206\n",
      "What...\n",
      "Processing item 82/206\n",
      "How ...\n",
      "Processing item 83/206\n",
      "What...\n",
      "Processing item 84/206\n",
      "What...\n",
      "Processing item 85/206\n",
      "How ...\n",
      "Processing item 86/206\n",
      "What...\n",
      "Processing item 87/206\n",
      "How ...\n",
      "Processing item 88/206\n",
      "What...\n",
      "Processing item 89/206\n",
      "What...\n",
      "Processing item 90/206\n",
      "What...\n",
      "Processing item 91/206\n",
      "How ...\n",
      "Processing item 92/206\n",
      "What...\n",
      "Processing item 93/206\n",
      "What...\n",
      "Processing item 94/206\n",
      "How ...\n",
      "Processing item 95/206\n",
      "Who ...\n",
      "Processing item 96/206\n",
      "What...\n",
      "Processing item 97/206\n",
      "How ...\n",
      "Processing item 98/206\n",
      "What...\n",
      "Processing item 99/206\n",
      "What...\n",
      "Processing item 100/206\n",
      "What...\n",
      "Processing item 101/206\n",
      "How ...\n",
      "Processing item 102/206\n",
      "What...\n",
      "Processing item 103/206\n",
      "What...\n",
      "Processing item 104/206\n",
      "How ...\n",
      "Processing item 105/206\n",
      "How ...\n",
      "Processing item 106/206\n",
      "Who ...\n",
      "Processing item 107/206\n",
      "What...\n",
      "Processing item 108/206\n",
      "How ...\n",
      "Processing item 109/206\n",
      "What...\n",
      "Processing item 110/206\n",
      "What...\n",
      "Processing item 111/206\n",
      "How ...\n",
      "Processing item 112/206\n",
      "How ...\n",
      "Processing item 113/206\n",
      "What...\n",
      "Processing item 114/206\n",
      "Wher...\n",
      "Processing item 115/206\n",
      "Can ...\n",
      "Processing item 116/206\n",
      "What...\n",
      "Processing item 117/206\n",
      "How ...\n",
      "Processing item 118/206\n",
      "Can ...\n",
      "Processing item 119/206\n",
      "How ...\n",
      "Processing item 120/206\n",
      "What...\n",
      "Processing item 121/206\n",
      "What...\n",
      "Processing item 122/206\n",
      "What...\n",
      "Processing item 123/206\n",
      "How ...\n",
      "Processing item 124/206\n",
      "What...\n",
      "Processing item 125/206\n",
      "What...\n",
      "Processing item 126/206\n",
      "How ...\n",
      "Processing item 127/206\n",
      "What...\n",
      "Processing item 128/206\n",
      "How ...\n",
      "Processing item 129/206\n",
      "How ...\n",
      "Processing item 130/206\n",
      "What...\n",
      "Processing item 131/206\n",
      "What...\n",
      "Processing item 132/206\n",
      "What...\n",
      "Processing item 133/206\n",
      "How ...\n",
      "Processing item 134/206\n",
      "What...\n",
      "Processing item 135/206\n",
      "What...\n",
      "Processing item 136/206\n",
      "What...\n",
      "Processing item 137/206\n",
      "What...\n",
      "Processing item 138/206\n",
      "What...\n",
      "Processing item 139/206\n",
      "What...\n",
      "Processing item 140/206\n",
      "How ...\n",
      "Processing item 141/206\n",
      "What...\n",
      "Processing item 142/206\n",
      "How ...\n",
      "Processing item 143/206\n",
      "What...\n",
      "Processing item 144/206\n",
      "What...\n",
      "Processing item 145/206\n",
      "What...\n",
      "Processing item 146/206\n",
      "How ...\n",
      "Processing item 147/206\n",
      "What...\n",
      "Processing item 148/206\n",
      "What...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 149/206\n",
      "What...\n",
      "Processing item 150/206\n",
      "What...\n",
      "Processing item 151/206\n",
      "How ...\n",
      "Processing item 152/206\n",
      "What...\n",
      "Processing item 153/206\n",
      "How ...\n",
      "Processing item 154/206\n",
      "How ...\n",
      "Processing item 155/206\n",
      "How ...\n",
      "Processing item 156/206\n",
      "How ...\n",
      "Processing item 157/206\n",
      "What...\n",
      "Processing item 158/206\n",
      "What...\n",
      "Processing item 159/206\n",
      "How ...\n",
      "Processing item 160/206\n",
      "How ...\n",
      "Processing item 161/206\n",
      "What...\n",
      "Processing item 162/206\n",
      "What...\n",
      "Processing item 163/206\n",
      "What...\n",
      "Processing item 164/206\n",
      "What...\n",
      "Processing item 165/206\n",
      "What...\n",
      "Processing item 166/206\n",
      "What...\n",
      "Processing item 167/206\n",
      "What...\n",
      "Processing item 168/206\n",
      "How ...\n",
      "Processing item 169/206\n",
      "How ...\n",
      "Processing item 170/206\n",
      "How ...\n",
      "Processing item 171/206\n",
      "How ...\n",
      "Processing item 172/206\n",
      "What...\n",
      "Processing item 173/206\n",
      "How ...\n",
      "Processing item 174/206\n",
      "What...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 175/206\n",
      "What...\n",
      "Processing item 176/206\n",
      "How ...\n",
      "Processing item 177/206\n",
      "How ...\n",
      "Processing item 178/206\n",
      "How ...\n",
      "Processing item 179/206\n",
      "What...\n",
      "Processing item 180/206\n",
      "What...\n",
      "Processing item 181/206\n",
      "How ...\n",
      "Processing item 182/206\n",
      "How ...\n",
      "Processing item 183/206\n",
      "How ...\n",
      "Processing item 184/206\n",
      "How ...\n",
      "Processing item 185/206\n",
      "What...\n",
      "Processing item 186/206\n",
      "What...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 187/206\n",
      "How ...\n",
      "Processing item 188/206\n",
      "How ...\n",
      "Processing item 189/206\n",
      "What...\n",
      "Processing item 190/206\n",
      "How ...\n",
      "Processing item 191/206\n",
      "What...\n",
      "Processing item 192/206\n",
      "How ...\n",
      "Processing item 193/206\n",
      "How ...\n",
      "Processing item 194/206\n",
      "What...\n",
      "Processing item 195/206\n",
      "How ...\n",
      "Processing item 196/206\n",
      "What...\n",
      "Processing item 197/206\n",
      "How ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 198/206\n",
      "What...\n",
      "Processing item 199/206\n",
      "How ...\n",
      "Processing item 200/206\n",
      "What...\n",
      "Processing item 201/206\n",
      "How ...\n",
      "Processing item 202/206\n",
      "What...\n",
      "Processing item 203/206\n",
      "What...\n",
      "Processing item 204/206\n",
      "What...\n",
      "Processing item 205/206\n",
      "How ...\n",
      "Processing item 206/206\n",
      "What...\n",
      "Features in dataset: ['user_input', 'retrieved_contexts', 'response']\n",
      "Total samples in dataset: 206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71d285c68104f9493ed57f49e42ef77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[770]: OutputParserException(Invalid json output: The statements are consistent with the provided context. Therefore, the corrected output string is:\n",
      "{\n",
      "  \"statements\": [\n",
      "    {\n",
      "      \"statement\": \"To obtain a Danish tax card, an individual must apply for a Danish tax card.\",\n",
      "      \"reason\": \"The context states 'Apply for a Danish tax card' and explains the process of applying for it, indicating that an application is required.\",\n",
      "      \"verdict\": 1\n",
      "    },\n",
      "    {\n",
      "      \"statement\": \"To obtain a Danish tax card, an individual must also apply for a personal tax number.\",\n",
      "      \"reason\": \"The context mentions 'Apply for a Danish tax card and a personal tax number' together, implying that both applications are necessary.\",\n",
      "      \"verdict\": 1\n",
      "    },\n",
      "    {\n",
      "      \"statement\": \"The application for the Danish tax card and the personal tax number can be completed online.\",\n",
      "      \"reason\": \"The text describes online procedures for applying for both the tax card and the personal tax number, including online forms and system access.\",\n",
      "      \"verdict\": 1\n",
      "    },\n",
      "    {\n",
      "      \"statement\": \"The online application is processed through the Danish Tax Agency's system.\",\n",
      "      \"reason\": \"The context states 'You use MitID to log on to E-tax (TastSelv)', which is the self-service system of the Danish Tax Agency, indicating online processing.\",\n",
      "      \"verdict\": 1\n",
      "    },\n",
      "    {\n",
      "      \"statement\": \"Registering for MitID, the Danish electronic ID, is necessary to access the self-service system.\",\n",
      "      \"reason\": \"The text states 'You will also need to get MitID, which is your Danish electronic ID, your digital signature' and 'You use MitID to log on to E-tax', implying registration for MitID is necessary for system access.\",\n",
      "      \"verdict\": 1\n",
      "    },\n",
      "    {\n",
      "      \"statement\": \"The self-service system includes services such as E-tax and TastSelv.\",\n",
      "      \"reason\": \"The context explicitly mentions 'E-tax (TastSelv)' as the self-service system used for tax-related services.\",\n",
      "      \"verdict\": 1\n",
      "    },\n",
      "    {\n",
      "      \"statement\": \"Non-Danish employees can find additional information on the specified website.\",\n",
      "      \"reason\": \"The context provides URLs and information about services for non-Danish employees, indicating they can find more info on the specified website.\",\n",
      "      \"verdict\": 1\n",
      "    },\n",
      "    {\n",
      "      \"statement\": \"Non-Danish employees can submit their application for a tax card at the specified URL.\",\n",
      "      \"reason\": \"The text states 'Apply for a Danish tax card and a personal tax number' and provides instructions to log on and submit forms via the online system, which applies to non-Danish employees as well.\",\n",
      "      \"verdict\": 1\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "Processing item 1/206\n",
      "How ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 2/206\n",
      "How ...\n",
      "Processing item 3/206\n",
      "What...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 4/206\n",
      "When...\n",
      "Processing item 5/206\n",
      "How ...\n",
      "Processing item 6/206\n",
      "What...\n",
      "Processing item 7/206\n",
      "Can ...\n",
      "Processing item 8/206\n",
      "How ...\n",
      "Processing item 9/206\n",
      "Wher...\n",
      "Processing item 10/206\n",
      "What...\n",
      "Processing item 11/206\n",
      "How ...\n",
      "Processing item 12/206\n",
      "What...\n",
      "Processing item 13/206\n",
      "Can ...\n",
      "Processing item 14/206\n",
      "How ...\n",
      "Processing item 15/206\n",
      "What...\n",
      "Processing item 16/206\n",
      "How ...\n",
      "Processing item 17/206\n",
      "Can ...\n",
      "Processing item 18/206\n",
      "Can ...\n",
      "Processing item 19/206\n",
      "What...\n",
      "Processing item 20/206\n",
      "How ...\n",
      "Processing item 21/206\n",
      "Who ...\n",
      "Processing item 22/206\n",
      "Can ...\n",
      "Processing item 23/206\n",
      "What...\n",
      "Processing item 24/206\n",
      "How ...\n",
      "Processing item 25/206\n",
      "What...\n",
      "Processing item 26/206\n",
      "What...\n",
      "Processing item 27/206\n",
      "How ...\n",
      "Processing item 28/206\n",
      "Wher...\n",
      "Processing item 29/206\n",
      "What...\n",
      "Processing item 30/206\n",
      "Can ...\n",
      "Processing item 31/206\n",
      "Are ...\n",
      "Processing item 32/206\n",
      "How ...\n",
      "Processing item 33/206\n",
      "How ...\n",
      "Processing item 34/206\n",
      "What...\n",
      "Processing item 35/206\n",
      "How ...\n",
      "Processing item 36/206\n",
      "Can ...\n",
      "Processing item 37/206\n",
      "How ...\n",
      "Processing item 38/206\n",
      "What...\n",
      "Processing item 39/206\n",
      "What...\n",
      "Processing item 40/206\n",
      "Do I...\n",
      "Processing item 41/206\n",
      "How ...\n",
      "Processing item 42/206\n",
      "How ...\n",
      "Processing item 43/206\n",
      "Do I...\n",
      "Processing item 44/206\n",
      "What...\n",
      "Processing item 45/206\n",
      "Can ...\n",
      "Processing item 46/206\n",
      "How ...\n",
      "Processing item 47/206\n",
      "What...\n",
      "Processing item 48/206\n",
      "Can ...\n",
      "Processing item 49/206\n",
      "Can ...\n",
      "Processing item 50/206\n",
      "What...\n",
      "Processing item 51/206\n",
      "Can ...\n",
      "Processing item 52/206\n",
      "Is i...\n",
      "Processing item 53/206\n",
      "How ...\n",
      "Processing item 54/206\n",
      "What...\n",
      "Processing item 55/206\n",
      "What...\n",
      "Processing item 56/206\n",
      "How ...\n",
      "Processing item 57/206\n",
      "Are ...\n",
      "Processing item 58/206\n",
      "What...\n",
      "Processing item 59/206\n",
      "How ...\n",
      "Processing item 60/206\n",
      "What...\n",
      "Processing item 61/206\n",
      "Can ...\n",
      "Processing item 62/206\n",
      "What...\n",
      "Processing item 63/206\n",
      "What...\n",
      "Processing item 64/206\n",
      "How ...\n",
      "Processing item 65/206\n",
      "Are ...\n",
      "Processing item 66/206\n",
      "What...\n",
      "Processing item 67/206\n",
      "How ...\n",
      "Processing item 68/206\n",
      "What...\n",
      "Processing item 69/206\n",
      "What...\n",
      "Processing item 70/206\n",
      "How ...\n",
      "Processing item 71/206\n",
      "What...\n",
      "Processing item 72/206\n",
      "What...\n",
      "Processing item 73/206\n",
      "Can ...\n",
      "Processing item 74/206\n",
      "How ...\n",
      "Processing item 75/206\n",
      "What...\n",
      "Processing item 76/206\n",
      "Are ...\n",
      "Processing item 77/206\n",
      "What...\n",
      "Processing item 78/206\n",
      "Can ...\n",
      "Processing item 79/206\n",
      "What...\n",
      "Processing item 80/206\n",
      "How ...\n",
      "Processing item 81/206\n",
      "What...\n",
      "Processing item 82/206\n",
      "How ...\n",
      "Processing item 83/206\n",
      "What...\n",
      "Processing item 84/206\n",
      "What...\n",
      "Processing item 85/206\n",
      "How ...\n",
      "Processing item 86/206\n",
      "What...\n",
      "Processing item 87/206\n",
      "How ...\n",
      "Processing item 88/206\n",
      "What...\n",
      "Processing item 89/206\n",
      "What...\n",
      "Processing item 90/206\n",
      "What...\n",
      "Processing item 91/206\n",
      "How ...\n",
      "Processing item 92/206\n",
      "What...\n",
      "Processing item 93/206\n",
      "What...\n",
      "Processing item 94/206\n",
      "How ...\n",
      "Processing item 95/206\n",
      "Who ...\n",
      "Processing item 96/206\n",
      "What...\n",
      "Processing item 97/206\n",
      "How ...\n",
      "Processing item 98/206\n",
      "What...\n",
      "Processing item 99/206\n",
      "What...\n",
      "Processing item 100/206\n",
      "What...\n",
      "Processing item 101/206\n",
      "How ...\n",
      "Processing item 102/206\n",
      "What...\n",
      "Processing item 103/206\n",
      "What...\n",
      "Processing item 104/206\n",
      "How ...\n",
      "Processing item 105/206\n",
      "How ...\n",
      "Processing item 106/206\n",
      "Who ...\n",
      "Processing item 107/206\n",
      "What...\n",
      "Processing item 108/206\n",
      "How ...\n",
      "Processing item 109/206\n",
      "What...\n",
      "Processing item 110/206\n",
      "What...\n",
      "Processing item 111/206\n",
      "How ...\n",
      "Processing item 112/206\n",
      "How ...\n",
      "Processing item 113/206\n",
      "What...\n",
      "Processing item 114/206\n",
      "Wher...\n",
      "Processing item 115/206\n",
      "Can ...\n",
      "Processing item 116/206\n",
      "What...\n",
      "Processing item 117/206\n",
      "How ...\n",
      "Processing item 118/206\n",
      "Can ...\n",
      "Processing item 119/206\n",
      "How ...\n",
      "Processing item 120/206\n",
      "What...\n",
      "Processing item 121/206\n",
      "What...\n",
      "Processing item 122/206\n",
      "What...\n",
      "Processing item 123/206\n",
      "How ...\n",
      "Processing item 124/206\n",
      "What...\n",
      "Processing item 125/206\n",
      "What...\n",
      "Processing item 126/206\n",
      "How ...\n",
      "Processing item 127/206\n",
      "What...\n",
      "Processing item 128/206\n",
      "How ...\n",
      "Processing item 129/206\n",
      "How ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 130/206\n",
      "What...\n",
      "Processing item 131/206\n",
      "What...\n",
      "Processing item 132/206\n",
      "What...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 133/206\n",
      "How ...\n",
      "Processing item 134/206\n",
      "What...\n",
      "Processing item 135/206\n",
      "What...\n",
      "Processing item 136/206\n",
      "What...\n",
      "Processing item 137/206\n",
      "What...\n",
      "Processing item 138/206\n",
      "What...\n",
      "Processing item 139/206\n",
      "What...\n",
      "Processing item 140/206\n",
      "How ...\n",
      "Processing item 141/206\n",
      "What...\n",
      "Processing item 142/206\n",
      "How ...\n",
      "Processing item 143/206\n",
      "What...\n",
      "Processing item 144/206\n",
      "What...\n",
      "Processing item 145/206\n",
      "What...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 146/206\n",
      "How ...\n",
      "Processing item 147/206\n",
      "What...\n",
      "Processing item 148/206\n",
      "What...\n",
      "Processing item 149/206\n",
      "What...\n",
      "Processing item 150/206\n",
      "What...\n",
      "Processing item 151/206\n",
      "How ...\n",
      "Processing item 152/206\n",
      "What...\n",
      "Processing item 153/206\n",
      "How ...\n",
      "Processing item 154/206\n",
      "How ...\n",
      "Processing item 155/206\n",
      "How ...\n",
      "Processing item 156/206\n",
      "How ...\n",
      "Processing item 157/206\n",
      "What...\n",
      "Processing item 158/206\n",
      "What...\n",
      "Processing item 159/206\n",
      "How ...\n",
      "Processing item 160/206\n",
      "How ...\n",
      "Processing item 161/206\n",
      "What...\n",
      "Processing item 162/206\n",
      "What...\n",
      "Processing item 163/206\n",
      "What...\n",
      "Processing item 164/206\n",
      "What...\n",
      "Processing item 165/206\n",
      "What...\n",
      "Processing item 166/206\n",
      "What...\n",
      "Processing item 167/206\n",
      "What...\n",
      "Processing item 168/206\n",
      "How ...\n",
      "Processing item 169/206\n",
      "How ...\n",
      "Processing item 170/206\n",
      "How ...\n",
      "Processing item 171/206\n",
      "How ...\n",
      "Processing item 172/206\n",
      "What...\n",
      "Processing item 173/206\n",
      "How ...\n",
      "Processing item 174/206\n",
      "What...\n",
      "Processing item 175/206\n",
      "What...\n",
      "Processing item 176/206\n",
      "How ...\n",
      "Processing item 177/206\n",
      "How ...\n",
      "Processing item 178/206\n",
      "How ...\n",
      "Processing item 179/206\n",
      "What...\n",
      "Processing item 180/206\n",
      "What...\n",
      "Processing item 181/206\n",
      "How ...\n",
      "Processing item 182/206\n",
      "How ...\n",
      "Processing item 183/206\n",
      "How ...\n",
      "Processing item 184/206\n",
      "How ...\n",
      "Processing item 185/206\n",
      "What...\n",
      "Processing item 186/206\n",
      "What...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 187/206\n",
      "How ...\n",
      "Processing item 188/206\n",
      "How ...\n",
      "Processing item 189/206\n",
      "What...\n",
      "Processing item 190/206\n",
      "How ...\n",
      "Processing item 191/206\n",
      "What...\n",
      "Processing item 192/206\n",
      "How ...\n",
      "Processing item 193/206\n",
      "How ...\n",
      "Processing item 194/206\n",
      "What...\n",
      "Processing item 195/206\n",
      "How ...\n",
      "Processing item 196/206\n",
      "What...\n",
      "Processing item 197/206\n",
      "How ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The completion for index 0 has been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item 198/206\n",
      "What...\n",
      "Processing item 199/206\n",
      "How ...\n",
      "Processing item 200/206\n",
      "What...\n",
      "Processing item 201/206\n",
      "How ...\n",
      "Processing item 202/206\n",
      "What...\n",
      "Processing item 203/206\n",
      "What...\n",
      "Processing item 204/206\n",
      "What...\n",
      "Processing item 205/206\n",
      "How ...\n",
      "Processing item 206/206\n",
      "What...\n",
      "Features in dataset: ['user_input', 'retrieved_contexts', 'response']\n",
      "Total samples in dataset: 206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f384e1d9d2124ed499559b36b9ac2232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt n_l_i_statement_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[642]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt n_l_i_statement_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
      "Exception raised in Job[654]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
      "Exception raised in Job[718]: OutputParserException(Invalid json output: The statements provided are all explicitly supported by the context, which details the rules and procedures for cross-border workers in Denmark, including income thresholds, deductions, notification deadlines, and international tax agreements. Therefore, the verdict for each statement is 1, indicating they are directly inferable from the context.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE )\n",
      "Exception raised in Job[794]: OutputParserException(Invalid json output: The statements provided are consistent with the context. The context explicitly mentions reporting gains and losses in boxes 20 and 58, respectively, and that the reporting must be done via E-tax. It describes the calculation of gains as the difference between the selling price and the average purchase price, and states that the FIFO method is used to determine the average purchase price. Additionally, it emphasizes the importance of keeping documentation of transactions for accurate reporting and verification. Therefore, all seven statements are directly supported by the context and should be judged as 1.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE )\n"
     ]
    }
   ],
   "source": [
    "# dispatching = await evaluate_dispatching()\n",
    "# llm_only = await evaluate_llm_only()\n",
    "# baseline_rag = await evaluate_baseline_rag()\n",
    "reranker_rag = await evaluate_reranker_rag()\n",
    "dense_rag = await evaluate_dense_rag()\n",
    "dense_reranker_rag = await evaluate_dense_reranker_rag()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9798f66a",
   "metadata": {},
   "source": [
    "Read evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42a1008",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_only = pd.read_csv(os.path.join(DATASET_DIR, \"evaluation_llm_only.csv\"))\n",
    "baseline_rag = pd.read_csv(os.path.join(DATASET_DIR, \"evaluation_baseline_rag.csv\"))\n",
    "reranker_rag = pd.read_csv(os.path.join(DATASET_DIR, \"evaluation_reranker_rag.csv\"))\n",
    "dense_rag = pd.read_csv(os.path.join(DATASET_DIR, \"evaluation_dense_rag.csv\"))\n",
    "dense_reranker_rag = pd.read_csv(os.path.join(DATASET_DIR, \"evaluation_dense_reranker_rag.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cea506b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                    answer_relevancy_mean\n",
       " LLM Only                         0.770185\n",
       " Baseline RAG                     0.861880\n",
       " Reranker RAG                     0.842157\n",
       " Dense RAG                        0.852620\n",
       " Dense Reranker RAG               0.814216,\n",
       "                     llm_context_precision_without_reference  faithfulness  \\\n",
       " Baseline RAG                                       0.760344      0.937853   \n",
       " Reranker RAG                                       0.740952      0.914175   \n",
       " Dense RAG                                          0.767320      0.930787   \n",
       " Dense Reranker RAG                                 0.768606      0.919837   \n",
       " \n",
       "                     nv_context_relevance  \n",
       " Baseline RAG                    0.516990  \n",
       " Reranker RAG                    0.512136  \n",
       " Dense RAG                       0.626214  \n",
       " Dense Reranker RAG              0.623786  )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods = {\n",
    "    \"LLM Only\": llm_only,\n",
    "    \"Baseline RAG\": baseline_rag,\n",
    "    \"Reranker RAG\": reranker_rag,\n",
    "    \"Dense RAG\": dense_rag,\n",
    "    \"Dense Reranker RAG\": dense_reranker_rag,\n",
    "}\n",
    "\n",
    "# Compute mean and std for answer_relevancy for all methods,\n",
    "# and for other columns for RAG methods (Baseline, Reranker, Dense)\n",
    "columns_to_compare = [\"answer_relevancy\", \"llm_context_precision_without_reference\", \"faithfulness\", \"nv_context_relevance\"]\n",
    "\n",
    "# Compare answer_relevancy for all methods\n",
    "answer_relevancy_means = {method: df[\"answer_relevancy\"].mean() for method, df in methods.items()}\n",
    "answer_relevancy_df = pd.DataFrame.from_dict(answer_relevancy_means, orient=\"index\", columns=[\"answer_relevancy_mean\"])\n",
    "\n",
    "# Compare other metrics for RAG methods only\n",
    "rag_methods = {k: v for k, v in methods.items() if k != \"LLM Only\"}\n",
    "other_metrics = [\"llm_context_precision_without_reference\", \"faithfulness\", \"nv_context_relevance\"]\n",
    "other_metrics_means = {\n",
    "    method: {metric: df[metric].mean() for metric in other_metrics}\n",
    "    for method, df in rag_methods.items()\n",
    "}\n",
    "other_metrics_df = pd.DataFrame.from_dict(other_metrics_means, orient=\"index\")\n",
    "\n",
    "answer_relevancy_df, other_metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32bc7f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38118/270250590.py:33: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  overall_means_incl_relevancy = highlighted[[\"llm_context_precision_without_reference\", \"faithfulness\", \"nv_context_relevance\"]].applymap(lambda x: float(x.replace(\"**\", \"\"))) \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_context_precision_without_reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>nv_context_relevance</th>\n",
       "      <th>Best Overall</th>\n",
       "      <th>answer_relevancy_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline RAG</th>\n",
       "      <td>0.7603</td>\n",
       "      <td>**0.9379**</td>\n",
       "      <td>0.5170</td>\n",
       "      <td></td>\n",
       "      <td>**0.8619**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reranker RAG</th>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.5121</td>\n",
       "      <td></td>\n",
       "      <td>0.8422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense RAG</th>\n",
       "      <td>0.7673</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>**0.6262**</td>\n",
       "      <td>🏆</td>\n",
       "      <td>0.8526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense Reranker RAG</th>\n",
       "      <td>**0.7686**</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.6238</td>\n",
       "      <td></td>\n",
       "      <td>0.8142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   llm_context_precision_without_reference faithfulness  \\\n",
       "Baseline RAG                                        0.7603   **0.9379**   \n",
       "Reranker RAG                                        0.7410       0.9142   \n",
       "Dense RAG                                           0.7673       0.9308   \n",
       "Dense Reranker RAG                              **0.7686**       0.9198   \n",
       "\n",
       "                   nv_context_relevance Best Overall answer_relevancy_mean  \n",
       "Baseline RAG                     0.5170                         **0.8619**  \n",
       "Reranker RAG                     0.5121                             0.8422  \n",
       "Dense RAG                    **0.6262**            🏆                0.8526  \n",
       "Dense Reranker RAG               0.6238                             0.8142  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Highlight best in each metric (highest value)\n",
    "highlighted = other_metrics_df.copy()\n",
    "for col in highlighted.columns:\n",
    "    max_val = highlighted[col].max()\n",
    "    highlighted[col] = highlighted[col].apply(lambda x: f\"**{x:.4f}**\" if np.isclose(x, max_val) else f\"{x:.4f}\")\n",
    "\n",
    "# Find best overall (highest mean across metrics)\n",
    "overall_means = other_metrics_df.mean(axis=1)\n",
    "best_overall_method = overall_means.idxmax()\n",
    "\n",
    "# Add a column to indicate best overall\n",
    "highlighted[\"Best Overall\"] = \"\"\n",
    "highlighted.loc[best_overall_method, \"Best Overall\"] = \"🏆\"\n",
    "\n",
    "highlighted\n",
    "# Add answer_relevancy_mean to highlighted table and highlight best\n",
    "highlighted[\"answer_relevancy_mean\"] = answer_relevancy_df.loc[highlighted.index, \"answer_relevancy_mean\"].apply(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "max_relevancy = answer_relevancy_df[\"answer_relevancy_mean\"].max()\n",
    "for idx in highlighted.index:\n",
    "    val = answer_relevancy_df.loc[idx, \"answer_relevancy_mean\"]\n",
    "    if np.isclose(val, max_relevancy):\n",
    "        highlighted.at[idx, \"answer_relevancy_mean\"] = f\"**{val:.4f}**\"\n",
    "\n",
    "# Compute overall mean including answer_relevancy_mean\n",
    "metrics_for_overall = [\"llm_context_precision_without_reference\", \"faithfulness\", \"nv_context_relevance\", \"answer_relevancy_mean\"]\n",
    "\n",
    "# Convert answer_relevancy_mean to float for calculation\n",
    "highlighted[\"answer_relevancy_mean_float\"] = answer_relevancy_df.loc[highlighted.index, \"answer_relevancy_mean\"]\n",
    "\n",
    "overall_means_incl_relevancy = highlighted[[\"llm_context_precision_without_reference\", \"faithfulness\", \"nv_context_relevance\"]].applymap(lambda x: float(x.replace(\"**\", \"\"))) \\\n",
    "    .join(highlighted[\"answer_relevancy_mean_float\"]).mean(axis=1)\n",
    "\n",
    "best_overall_method_incl_relevancy = overall_means_incl_relevancy.idxmax()\n",
    "\n",
    "# Update Best Overall column\n",
    "highlighted[\"Best Overall\"] = \"\"\n",
    "highlighted.loc[best_overall_method_incl_relevancy, \"Best Overall\"] = \"🏆\"\n",
    "\n",
    "# Remove helper column\n",
    "highlighted = highlighted.drop(columns=[\"answer_relevancy_mean_float\"])\n",
    "\n",
    "highlighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343b35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec3adf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
